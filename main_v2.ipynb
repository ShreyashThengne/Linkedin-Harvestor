{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as ec\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "creds = pd.read_csv('creds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "id, pw = creds.iloc[0,:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_delay = 3  # seconds\n",
    "# this I am putting so that we will be able to capture the html code because page does not load the very instant\n",
    "# it needs some time, varying with respect to speed of internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Edge()\n",
    "driver.get('https://www.linkedin.com/login')\n",
    "actions = ActionChains(driver)\n",
    "\n",
    "def create_soup(source_code):\n",
    "    return BeautifulSoup(source_code, 'html.parser')\n",
    "\n",
    "\n",
    "class Scraper:\n",
    "    def __init__(self, id, pw):\n",
    "        self.id = id\n",
    "        self.pw = pw\n",
    "\n",
    "    def login(self):\n",
    "        driver.find_element(By.ID, \"username\").send_keys(self.id)\n",
    "        driver.find_element(By.ID, \"password\").send_keys(self.pw)\n",
    "        driver.find_element(By.CLASS_NAME, \"login__form_action_container\").click()\n",
    "    \n",
    "    def search(self, query):\n",
    "        driver.find_element(By.ID, 'global-nav-search').click()\n",
    "        actions.send_keys(query).send_keys(Keys.ENTER).perform()\n",
    "        WebDriverWait(driver, 10).until(ec.presence_of_all_elements_located((By.CLASS_NAME, \"search-reusables__primary-filter\")))[0].click()\n",
    "        actions.send_keys(Keys.ESCAPE).perform()\n",
    "    \n",
    "    def link_scraper(self, pages):\n",
    "        profile_links = []\n",
    "        for k in range(pages):\n",
    "            # driver.implicitly_wait(10)\n",
    "            time.sleep(page_delay)\n",
    "            soup = create_soup(driver.page_source)\n",
    "\n",
    "            for i in soup.find_all('li', {'class':\"reusable-search__result-container\"}):\n",
    "                try:\n",
    "                    profile_links.append(i.find('a',{'class':\"app-aware-link scale-down\"}).get('href'))\n",
    "                except:\n",
    "                    print('Ad Encountered')\n",
    "\n",
    "            print(f\"Page {k + 1}\")\n",
    "\n",
    "            actions.send_keys(Keys.END)\n",
    "            time.sleep(page_delay)\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            WebDriverWait(driver, 10).until(ec.presence_of_element_located((By.CLASS_NAME, \"artdeco-pagination__button--next\"))).click()\n",
    "            \n",
    "        return profile_links\n",
    "\n",
    "    def run(self, query, pages):\n",
    "        '''\n",
    "        id, data (list->dict)\n",
    "        '''\n",
    "        \n",
    "        self.search(query)\n",
    "        profiles = self.link_scraper(pages)\n",
    "        id = 1\n",
    "        data = []\n",
    "        for p in profiles:\n",
    "            print(p)\n",
    "            profile_obj = Profile(p)\n",
    "            data.append({\n",
    "                'id':id,\n",
    "                'data': profile_obj.get_all_the_data_my_slave()\n",
    "            })\n",
    "            id += 1 \n",
    "        \n",
    "        return data\n",
    "\n",
    "class Profile:\n",
    "    def __init__(self, link):\n",
    "        driver.get(link)\n",
    "        time.sleep(page_delay)\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        self.profile_link = driver.current_url\n",
    "        self.soup = create_soup(driver.page_source)\n",
    "        self.cards = self.soup.find_all('section', {\"class\": \"artdeco-card pv-profile-card break-words mt2\"})\n",
    "        self.sections_available = {}\n",
    "        for i in self.cards:\n",
    "            self.sections_available[i.find().get('id')] = True\n",
    "\n",
    "\n",
    "    def get_contact_data(self):\n",
    "        '''\n",
    "        Website, Email, IM, Birthday, Connected, Address, Phone, name, profile_link (dict)\n",
    "        '''\n",
    "\n",
    "        try:\n",
    "            # WebDriverWait(driver,10)\n",
    "            name = self.soup.find('div', {'class', 'mt2 relative'}).findChild('h1',{'class':'text-heading-xlarge inline t-24 v-align-middle break-words'}).text\n",
    "\n",
    "            driver.get(self.profile_link + 'overlay/contact-info/')\n",
    "            obj_list = WebDriverWait(driver, 10).until(ec.presence_of_all_elements_located((By.CLASS_NAME, \"pv-contact-info__contact-type\")))\n",
    "            contact_info = []\n",
    "            for sel_obj in obj_list:\n",
    "                contact_info.append(sel_obj.text.split(\"\\n\"))\n",
    "            try:\n",
    "                contact_info.remove(['Birthday'])\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            def nested_list_to_dict(l):\n",
    "                d = {}\n",
    "                for i in l:\n",
    "                    d[i[0]] = i[1]\n",
    "                return d\n",
    "\n",
    "            actions = ActionChains(driver)\n",
    "            actions.send_keys(Keys.ESCAPE).perform()\n",
    "            contact_info_dict = nested_list_to_dict(contact_info)\n",
    "            contact_info_dict.pop('Birthday')\n",
    "            contact_info_dict['name'] = name\n",
    "\n",
    "            if contact_info_dict == []:\n",
    "                contact_info_dict = self.get_contact_data()\n",
    "            \n",
    "            city = self.soup.find(\"span\", {'class':\"text-body-small inline t-black--light break-words\"}).text.strip()\n",
    "            contact_info_dict['city'] = city\n",
    "            contact_info_dict['profile_link'] = contact_info_dict[contact_info_dict['name'].split(\" \")[0] + \"’s \" + 'Profile']\n",
    "            contact_info_dict.pop(contact_info_dict['name'].split(\" \")[0] + \"’s \" + 'Profile')\n",
    "\n",
    "            for field in ['Website', 'Email', 'IM','Connected', 'city', 'Address', 'Phone', 'name', 'profile_link']:\n",
    "                if field not in contact_info_dict:\n",
    "                    contact_info_dict[field] = None\n",
    "            return contact_info_dict\n",
    "        \n",
    "        except Exception as error:\n",
    "            print(error)\n",
    "            return self.get_contact_data()\n",
    "    \n",
    "\n",
    "    def get_followers_and_about(self):\n",
    "        '''\n",
    "        connections, followers, about (tuple)\n",
    "        '''\n",
    "        \n",
    "        about = None\n",
    "        connections = None\n",
    "        followers = None\n",
    "\n",
    "        connections = self.soup.find('div', {'class', \"mt2 relative\"}).findNextSibling().text.strip()\n",
    "        \n",
    "        for i in self.cards:\n",
    "            if i.find('div', {'id':'content_collections'}) != None:\n",
    "                followers = i.find('div', {'class':'pvs-header__title-container'}).text.strip().split()[1]\n",
    "                break\n",
    "\n",
    "        for i in self.cards:\n",
    "            if i.find('div', {'id':'about'}) != None:\n",
    "                about = i.find('div', {'class':\"display-flex ph5 pv3\"}).text.strip()\n",
    "                break\n",
    "\n",
    "        if about != None:\n",
    "            about = about[:len(about)//2]\n",
    "\n",
    "        return connections, followers, about\n",
    "    \n",
    "\n",
    "    def get_experience(self):\n",
    "        '''\n",
    "        For all job roles: role, company, job_type, from, to, duration (list->dict)\n",
    "        '''\n",
    "\n",
    "        try:\n",
    "            driver.get(self.profile_link + 'details/experience/')\n",
    "            # WebDriverWait(driver, 10)\n",
    "            time.sleep(page_delay)\n",
    "            soup = create_soup(driver.page_source)\n",
    "\n",
    "            all_exp = soup.find_all('li', {'class', 'pvs-list__paged-list-item artdeco-list__item pvs-list__item--line-separated pvs-list__item--one-column'})\n",
    "\n",
    "            def extract_exp_data(sample):\n",
    "                role = sample.find('div', {'class', 'display-flex flex-wrap align-items-center full-height'}).text.strip()\n",
    "                role = role[:len(role)//2]\n",
    "\n",
    "                company_and_job_type = sample.find('span', {'class', 't-14 t-normal'}).text.strip()\n",
    "                company_and_job_type = company_and_job_type[:len(company_and_job_type)//2].split(\" · \")\n",
    "                company = company_and_job_type[0]\n",
    "                \n",
    "                try:\n",
    "                    job_type = company_and_job_type[1]\n",
    "                except:\n",
    "                    job_type = None\n",
    "                try:\n",
    "                    period, duration = sample.find('span', {'class', \"pvs-entity__caption-wrapper\"}).text.split(' · ')\n",
    "                    period = period.split(\" - \")\n",
    "                except:\n",
    "                    # this is a special case when an employee has worked more than one positions in the same company\n",
    "                    # used 'extend' instead of 'append' for this reason only\n",
    "                    company = role\n",
    "                    job_type = None\n",
    "                    multiples = soup.find_all('li', {'class':'pvs-list__paged-list-item  pvs-list__item--one-column'})\n",
    "                    jobs = []\n",
    "                    for x in multiples:\n",
    "                        role = x.find('div', {'class', 'display-flex flex-wrap align-items-center full-height'}).text.strip()\n",
    "                        job_type = x.find('span', {'class':'t-14 t-normal'}).text.strip()\n",
    "                        period, duration = sample.find('span', {'class', \"pvs-entity__caption-wrapper\"}).text.split(' · ')\n",
    "                        period = period.split(\" - \")\n",
    "                        try:\n",
    "                            duration = int(duration.split(\" \")[0]) * 12 + int(duration.split(\" \")[2])\n",
    "                        except:\n",
    "                            if duration.split(\" \")[0] == 'yrs':\n",
    "                                duration = int(duration.split(\" \")[0]) * 12\n",
    "                            else: duration = int(duration.split(\" \")[0])\n",
    "                        jobs.append({'role':role, 'company':company, 'job_type':job_type, 'from':period['from'], 'to':period['to'], 'duration':duration})\n",
    "                    return jobs\n",
    "                \n",
    "\n",
    "                try:\n",
    "                    duration = int(duration.split(\" \")[0]) * 12 + int(duration.split(\" \")[2])\n",
    "                except:\n",
    "                    if duration.split(\" \")[0] == 'yrs':\n",
    "                        duration = int(duration.split(\" \")[0]) * 12\n",
    "                    else: duration = int(duration.split(\" \")[0])\n",
    "\n",
    "                try:\n",
    "                    period = {'from': datetime.strptime(period[0], \"%b %Y\"), 'to': datetime.strptime(period[1], \"%b %Y\")}\n",
    "                except:\n",
    "                    period = {'from': datetime.strptime(period[0], \"%b %Y\"), 'to': datetime.strptime(datetime.now().strftime(\"%b %Y\"), \"%b %Y\")}\n",
    "                return [{'role':role, 'company':company, 'job_type':job_type, 'from':period['from'], 'to':period['to'], 'duration':duration}]\n",
    "\n",
    "            all_experiences = []\n",
    "            for i in  all_exp:\n",
    "                all_experiences.extend(extract_exp_data(i))\n",
    "\n",
    "            if all_experiences == []:\n",
    "                print('repeating, since empty!')\n",
    "                all_experiences = self.get_experience()\n",
    "\n",
    "            \n",
    "            return all_experiences\n",
    "        \n",
    "        except Exception as error:\n",
    "            print(\"exp \", error)\n",
    "            return self.get_experience()\n",
    "    \n",
    "\n",
    "    def get_education(self):\n",
    "        '''\n",
    "        For all edu: college, degree, from, to (list->dict)\n",
    "        '''\n",
    "\n",
    "        try:\n",
    "            driver.get(self.profile_link + 'details/education/')\n",
    "            # WebDriverWait(driver, 10)\n",
    "            time.sleep(page_delay)\n",
    "            soup = create_soup(driver.page_source)\n",
    "\n",
    "            all_edu = soup.find_all('li', {'class', 'pvs-list__paged-list-item artdeco-list__item pvs-list__item--line-separated pvs-list__item--one-column'})\n",
    "\n",
    "            def extract_education_data(sample):\n",
    "                college = sample.find('div', {'class', 'display-flex flex-wrap align-items-center full-height'}).text.strip()\n",
    "                college = college[:len(college)//2]\n",
    "                degree = sample.find('span', {'class', 't-14 t-normal'}).text.strip()\n",
    "                degree = degree[:len(degree)//2]\n",
    "                try:\n",
    "                    period = sample.find('span', {'class', 'pvs-entity__caption-wrapper'}).text.strip().split(\" - \")\n",
    "                    period = {'from': period[0], 'to': period[1]}\n",
    "                except:\n",
    "                    period = {'from': None, 'to': None}\n",
    "                return {'college':college, 'degree':degree, 'from':period['from'], 'to':period['to']}\n",
    "\n",
    "            all_education = []\n",
    "            for i in  all_edu:\n",
    "                all_education.append(extract_education_data(i))\n",
    "            \n",
    "            if all_education == []:\n",
    "                all_education = self.get_education()\n",
    "            \n",
    "            \n",
    "            return all_education\n",
    "        \n",
    "        except Exception as error:\n",
    "            print(\"edu \", error)\n",
    "            return self.get_education()\n",
    "        \n",
    "\n",
    "    def get_certifications(self):\n",
    "        '''\n",
    "        For all certs: name, org, issued, link (list->dict)\n",
    "        '''\n",
    "        try:\n",
    "            driver.get(self.profile_link + 'details/certifications/')\n",
    "            # WebDriverWait(driver, 10)\n",
    "            time.sleep(page_delay)\n",
    "            soup = create_soup(driver.page_source)\n",
    "\n",
    "            def extract_certifications(sample):\n",
    "                sample = all_certs[0]\n",
    "                name = sample.find('div', {'class', 'display-flex flex-wrap align-items-center full-height'}).text.strip()\n",
    "                organization = sample.find('span', {'class', 't-14 t-normal'}).text.strip()\n",
    "                organization = organization[:len(organization)//2]\n",
    "                try:\n",
    "                    issued = datetime.strptime(sample.find('span', {'class', 'pvs-entity__caption-wrapper'}).text.split(\"Issued\")[1].strip(), '%b %Y')\n",
    "                except:\n",
    "                    issued = None\n",
    "                try:\n",
    "                    link = sample.find('a', {'class', 'optional-action-target-wrapper artdeco-button artdeco-button--secondary artdeco-button--standard artdeco-button--2 artdeco-button--muted inline-flex justify-center align-self-flex-start button-placement-wrap'}).get('href')\n",
    "                except:\n",
    "                    link = None\n",
    "                return {'cert_name':name, 'cert_org': organization, 'cert_issued':issued, 'cert_link':link}\n",
    "\n",
    "            all_certs = soup.find_all('li', {'class', 'pvs-list__paged-list-item artdeco-list__item pvs-list__item--line-separated pvs-list__item--one-column'})\n",
    "\n",
    "            all_certification = []\n",
    "            for i in  all_certs:\n",
    "                all_certification.append(extract_certifications(i))\n",
    "\n",
    "            if all_certification == []:\n",
    "                all_certification = self.get_certifications()\n",
    "            \n",
    "\n",
    "            return all_certification\n",
    "        except Exception as error:\n",
    "            print(\"certs \",error)\n",
    "            return self.get_certifications()\n",
    "\n",
    " \n",
    "    def get_skills(self):\n",
    "        '''\n",
    "        Skills (list)\n",
    "        '''\n",
    "\n",
    "        try:\n",
    "            driver.get(self.profile_link + 'details/skills/')\n",
    "            # WebDriverWait(driver, 10)\n",
    "            time.sleep(page_delay)\n",
    "            soup = create_soup(driver.page_source)\n",
    "\n",
    "            all_skills = soup.find_all('li', {'class', 'pvs-list__paged-list-item artdeco-list__item pvs-list__item--line-separated pvs-list__item--one-column'})\n",
    "\n",
    "            def extract_skills(sample):\n",
    "                '''\n",
    "                skill\n",
    "                '''\n",
    "                skill = sample.find('div', {'class':\"display-flex flex-wrap align-items-center full-height\"}).text.strip()\n",
    "                skill = skill[:len(skill)//2]\n",
    "                return skill\n",
    "\n",
    "            skills = set()\n",
    "            for i in all_skills:\n",
    "                skills.add(extract_skills(i))\n",
    "            skills = list(skills)\n",
    "\n",
    "            if skills == []:\n",
    "                skills = self.get_skills()\n",
    "\n",
    "            \n",
    "        \n",
    "            \n",
    "            return skills\n",
    "        except Exception as error:\n",
    "            print(\"skills \", error)\n",
    "            return self.get_skills()\n",
    "        \n",
    "    \n",
    "    def get_languages(self):\n",
    "        '''\n",
    "        For all languages: languages, profiency (list->dict)\n",
    "        '''\n",
    "\n",
    "        try:\n",
    "            driver.get(self.profile_link + 'details/languages/')\n",
    "            # wait = WebDriverWait(driver, 10)\n",
    "            time.sleep(page_delay)\n",
    "            soup = create_soup(driver.page_source)\n",
    "\n",
    "            all_langs = soup.find_all('li', {'class', 'pvs-list__paged-list-item artdeco-list__item pvs-list__item--line-separated pvs-list__item--one-column'})\n",
    "\n",
    "            def extract_langs(sample):\n",
    "                lang = sample.find('div', {'class':\"display-flex flex-wrap align-items-center full-height\"}).text.strip()\n",
    "                lang = lang[:len(lang)//2]\n",
    "                profiency = sample.find('span', {'class':\"t-14 t-normal t-black--light\"}).text.strip()\n",
    "                profiency = profiency[:len(profiency)//2]\n",
    "\n",
    "                return {'language':lang, 'profiency':profiency}\n",
    "\n",
    "            langs = []\n",
    "            for i in all_langs:\n",
    "                langs.append(extract_langs(i))\n",
    "            \n",
    "            if langs == []:\n",
    "                langs = self.get_languages()\n",
    "            \n",
    "            \n",
    "            \n",
    "            return langs\n",
    "        except Exception as error:\n",
    "            print(\"Lang \",error)\n",
    "            return self.get_languages\n",
    "    \n",
    "\n",
    "    def get_awards(self):\n",
    "        '''\n",
    "        For all awards: award_name, org, date (list->dict)\n",
    "        '''\n",
    "        try:\n",
    "            driver.get(self.profile_link + 'details/honors/')\n",
    "            # wait = WebDriverWait(driver, 10)\n",
    "            time.sleep(page_delay)\n",
    "            soup = create_soup(driver.page_source)\n",
    "\n",
    "            all_awards = soup.find_all('li', {'class', 'pvs-list__paged-list-item artdeco-list__item pvs-list__item--line-separated pvs-list__item--one-column'})\n",
    "\n",
    "            def extract_awards(sample):\n",
    "\n",
    "                award_name = sample.find('div', {'class':\"display-flex flex-wrap align-items-center full-height\"}).text.strip()\n",
    "                award_name = award_name[:len(award_name)//2]\n",
    "                try:\n",
    "                    org_and_date = sample.find('span', {'class':\"t-14 t-normal\"}).text.strip()\n",
    "                    org_and_date = org_and_date[:len(org_and_date)//2].split(' · ')\n",
    "                    org = org_and_date[0]\n",
    "                    try:\n",
    "                        date = datetime.strptime(org_and_date[1], '%b %Y')\n",
    "                    except:\n",
    "                        date = None\n",
    "                except:\n",
    "                    org = date = None\n",
    "                return {'award_name':award_name, 'org':org, 'date':date}\n",
    "\n",
    "\n",
    "            awards = []\n",
    "            for i in all_awards:\n",
    "                awards.append(extract_awards(i))\n",
    "            \n",
    "            if awards == []:\n",
    "                awards = self.get_awards()\n",
    "            \n",
    "\n",
    "            return awards\n",
    "        except Exception as error:\n",
    "            print('Awards ',error)\n",
    "            return self.get_awards\n",
    "        \n",
    "    \n",
    "    def get_all_the_data_my_slave(self):\n",
    "        contact = self.get_contact_data()\n",
    "        connections, followers, about = self.get_followers_and_about()\n",
    "        \n",
    "        try:\n",
    "            if self.sections_available['experience']:\n",
    "                experience = self.get_experience()\n",
    "        except:\n",
    "            experience = [{\n",
    "                'role':None,\n",
    "                'company': None,\n",
    "                'job_type': None,\n",
    "                'from': None,\n",
    "                'to': None,\n",
    "                'duration': None\n",
    "            }]\n",
    "        try:\n",
    "            if self.sections_available['education']:\n",
    "                education = self.get_education()\n",
    "        except:\n",
    "            education = [{\n",
    "                'college': None,\n",
    "                'degree': None,\n",
    "                'from': None,\n",
    "                'to': None\n",
    "            }]\n",
    "            \n",
    "\n",
    "        try:\n",
    "            if self.sections_available['licenses_and_certifications']:\n",
    "                certification =  self.get_certifications()\n",
    "        except:\n",
    "            certification = [{\n",
    "                'cert_name': None,\n",
    "                'cert_org': None,\n",
    "                'cert_issued': None,\n",
    "                'cert_link': None\n",
    "        }]\n",
    "\n",
    "        try:\n",
    "            if self.sections_available['skills']:\n",
    "                skills = self.get_skills()\n",
    "        except:\n",
    "            skills = [None]\n",
    "\n",
    "        try:\n",
    "            if self.sections_available['languages']:\n",
    "                languages = self.get_languages()\n",
    "        except:\n",
    "            languages = [{\n",
    "                'language': None,\n",
    "                'profiency': None\n",
    "            }]\n",
    "        try:\n",
    "            if self.sections_available['honors_and_awards']:\n",
    "                awards = self.get_awards()\n",
    "        except:\n",
    "            awards = [{\n",
    "                'award_name': None,\n",
    "                'org': None,\n",
    "                'date': None\n",
    "            }]\n",
    "\n",
    "\n",
    "        return {\n",
    "            'contact':contact,\n",
    "            'connections':connections,\n",
    "            'followers':followers,\n",
    "            'about':about,\n",
    "            'experience':experience,\n",
    "            'education':education,\n",
    "            'certification':certification,\n",
    "            'skills':skills,\n",
    "            'languages':languages,\n",
    "            'awards':awards\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = Scraper(id, pw)\n",
    "s1.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ad Encountered\n",
      "Page 1\n",
      "Page 2\n",
      "https://www.linkedin.com/in/abhishek-paithane-a617a3119?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAB17qCkBmg98cThWweg-le8H_f3D9ao8o9Q\n",
      "https://www.linkedin.com/in/suryank-dixit-858a47169?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACgzAAQBEugTXleiv4Aftv8j04N8fftcyXE\n",
      "https://www.linkedin.com/in/sohaagarwal93?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAB01p7UBVUuFU03bGyVpi9mz_DEoAM2VVls\n",
      "https://www.linkedin.com/in/pranay-gaikwad-9150b3190?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACzdVGEB8_ThOhGH-WuIJz4SRYByYjnBS_E\n",
      "https://www.linkedin.com/in/charan-kamarapu?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACsYnOwBRiabDme6MJsAmrvGq_i_i3Xe330\n",
      "https://www.linkedin.com/in/ashish-nimbalkar-602371152?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACS3hSIBdL7iQoMoPzy_1iYEVTRM7Kpg0Fc\n",
      "https://www.linkedin.com/in/prachi-wagh?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAADLprp4BmSQhnYZioZGJOFk5O4qOF1ZEVgA\n",
      "https://www.linkedin.com/in/ameya-vyavahare-ab9b721a2?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAC-Drq0BYzoLxihvfzIgq2eFdwQMi-38sV4\n",
      "https://www.linkedin.com/in/rishabh-agarwal-8987bb93?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABPfzjQBKsfUto-gYRy2_AVIVUGarwcKF70\n",
      "https://www.linkedin.com/in/abistarun?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAXE2BQB4GNWebSm9Ex4CkgdFfDOYViWoMQ\n",
      "https://www.linkedin.com/in/vandanpatel105?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACXskSMBj9IARKXihdfMhgPVCAxfB_2P6Bg\n",
      "https://www.linkedin.com/in/nikunjsoni14?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAB1BDikBoOE6o6epV1_HpoCWwvy53uPVN0A\n",
      "Awards  list index out of range\n",
      "https://www.linkedin.com/in/dhirajkelhe?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACBO7b0BqUac6J98AZWdD1W0h0Iw477irVo\n",
      "repeating, since empty!\n",
      "repeating, since empty!\n",
      "repeating, since empty!\n",
      "repeating, since empty!\n",
      "repeating, since empty!\n",
      "https://www.linkedin.com/in/dhrumil-kavathia-6a26bb16a?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAChTsRoB6tybPAkqItS2377WoGCbvbshmrI\n",
      "Awards  'NoneType' object has no attribute 'text'\n",
      "https://www.linkedin.com/in/shikharsonker07?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACfCA8wBRiOyVUQUi23Xh6Te8XqWAHrKqXM\n",
      "https://www.linkedin.com/in/swastikabisht?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAC2RI0wBlzqO51SPxD8YsxpbIZXqP1_mplw\n",
      "exp  invalid literal for int() with base 10: 'Hybrid'\n",
      "exp  invalid literal for int() with base 10: 'Hybrid'\n",
      "exp  invalid literal for int() with base 10: 'Hybrid'\n",
      "exp  invalid literal for int() with base 10: 'Hybrid'\n",
      "exp  invalid literal for int() with base 10: 'Hybrid'\n",
      "exp  invalid literal for int() with base 10: 'Hybrid'\n",
      "exp  invalid literal for int() with base 10: 'Hybrid'\n",
      "exp  invalid literal for int() with base 10: 'Hybrid'\n",
      "exp  invalid literal for int() with base 10: 'Hybrid'\n",
      "exp  invalid literal for int() with base 10: 'Hybrid'\n",
      "exp  invalid literal for int() with base 10: 'Hybrid'\n",
      "exp  invalid literal for int() with base 10: 'Hybrid'\n",
      "exp  invalid literal for int() with base 10: 'Hybrid'\n",
      "https://www.linkedin.com/in/mohit-shingane-1975a8199?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAC6KLQMBiFv_qvnLc84z7baPxUZtUI4wlmI\n",
      "repeating, since empty!\n",
      "repeating, since empty!\n",
      "repeating, since empty!\n",
      "repeating, since empty!\n",
      "repeating, since empty!\n",
      "repeating, since empty!\n",
      "repeating, since empty!\n",
      "repeating, since empty!\n",
      "repeating, since empty!\n",
      "repeating, since empty!\n",
      "repeating, since empty!\n",
      "repeating, since empty!\n",
      "repeating, since empty!\n",
      "repeating, since empty!\n",
      "repeating, since empty!\n",
      "repeating, since empty!\n",
      "https://www.linkedin.com/in/mayur-pawar-101a551b1?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAADF0f1EB8xmqcnf35KaQqa1_qYZ3YeaVS_s\n",
      "repeating, since empty!\n",
      "repeating, since empty!\n",
      "repeating, since empty!\n",
      "repeating, since empty!\n",
      "repeating, since empty!\n",
      "repeating, since empty!\n",
      "repeating, since empty!\n",
      "repeating, since empty!\n",
      "repeating, since empty!\n",
      "https://www.linkedin.com/in/shabbir-murtaza?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACijPm4B1GhIVBLYKLkWKy2SLl4lKF9e050\n",
      "https://www.linkedin.com/in/nayan-mahajan-n-1-25-1-n?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAADIfPqwBzN0y-gpn8DfYokqVnxONp-FpW4Q\n",
      "Lang  'NoneType' object has no attribute 'text'\n"
     ]
    }
   ],
   "source": [
    "data = s1.run(query = 'Amazon SDE', pages = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "linkedin_scraper_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
